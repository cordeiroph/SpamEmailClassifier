{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of it is to generate a model capable to classify a email as spam or not spam.\n",
    "\n",
    "The dataset used was from http://www2.aueb.gr/users/ion/data/enron-spam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aggga@gmail\n",
      "aggga@gmail\n"
     ]
    }
   ],
   "source": [
    "def getEmailServer(email):\n",
    "    email = email.replace(\".\", \" \")\n",
    "    emailVet = email.split()\n",
    "    matching = [s for s in emailVet if \"@\" in s] \n",
    "    return matching[0].replace(\"<\", \"\").replace(\">\", \"\")\n",
    "\n",
    "a = \"ahgha <aggga@gmail.com>\"\n",
    "b = \"aggga@gmail.com\"\n",
    "\n",
    "\n",
    "testA = getEmailServer(a)\n",
    "testB = getEmailServer(b)\n",
    "\n",
    "print(testA)\n",
    "print(testB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempStr = 'a b c44 66d e5e '\n",
    "\n",
    "clean = re.compile('[0-9]')\n",
    "tex = re.sub(clean, \" \", tempStr)\n",
    "\n",
    "print(tex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempSet = sorted(set(list(chain(*df[df['isSpam'] == True][\"wordsList\"].values))))\n",
    "\n",
    "\n",
    "print(tempSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(tempSet)\n",
    "\n",
    "print(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "words = lem.lemmatize('accommodations')\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text.ENGLISH_STOP_WORDS)\n",
    "\n",
    "print(type(text.ENGLISH_STOP_WORDS))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(chain(*df[\"wordsList\"].values))\n",
    "\n",
    "l = set(filter(lambda k : len(k) == 1, l))\n",
    "\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Apply cleaning method\n",
    "dfMaster['treatedMessage'] = dfMaster['messageStr'].apply(emailTextCleanner)\n",
    "\n",
    "#Remove stop words\n",
    "stop = txt.ENGLISH_STOP_WORDS\n",
    "dfMaster['treatedMessage'] = dfMaster['treatedMessage'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "dfMaster['treatedMessage'] = dfMaster['treatedMessage'].apply(\n",
    "    lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#Create a column with list of words\n",
    "dfMaster['wordsList'] = dfMaster['treatedMessage'].str.split().apply(lemmatizeList).apply(revomeWordsWithOneCharacter)\n",
    "\n",
    "#Create a columns to calculate the total amount of words\n",
    "dfMaster['totalTreatedWords'] = dfMaster['wordsList'].apply(lambda x : len(x))\n",
    "#dfMaster['treatedTextLen'] = dfMaster['treatedMessage'].apply(lambda x : len(x))\n",
    "#dfMaster['textLen'] = dfMaster['messageStr'].apply(lambda x : len(str(x)))\n",
    "dfMaster['uniqueWordsLen'] = dfMaster['wordsList'].apply(lambda x : len(set(x)))\n",
    "\n",
    "\n",
    "#Convert Date to a date time object\n",
    "#dfMaster['date'] = dfMaster['date'].apply(lambda x : str(x)).apply(lambda x : None if x == 'nan' else datetime.datetime.strptime(x, '%a, %d %b %Y %H:%M:%S %z'))\n",
    "\n",
    "#Create a Hour Column\n",
    "#dfMaster['hour'] = dfMaster['date'].apply(lambda x : None if x == None else x.hour)\n",
    "\n",
    "#Create a count to\n",
    "#dfMaster['toCount'] = dfMaster['to'].str.split(',').apply(lambda x : len(x) if isinstance(x, list) else 0)\n",
    "\n",
    "dfMaster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,12))\n",
    "grid = plt.GridSpec(2,4, wspace =0.3, hspace =0.5)\n",
    "pieMsg = fig.add_subplot(grid[0,0:3])\n",
    "barNonNull = fig.add_subplot(grid[1,0:3])\n",
    "barNull = fig.add_subplot(grid[0:2,3])\n",
    "\n",
    "\n",
    "pieMsg.pie([len(dfMaster[dfMaster['messageStr'].notnull()]), len(dfMaster[dfMaster['messageStr'].isnull()])], \n",
    "        labels=['Non Null', 'Null'], autopct='%1.0f%%', pctdistance=0.5, labeldistance=1.2)\n",
    "\n",
    "\n",
    "\n",
    "barAll.bar(\n",
    "    dfMaster['messageType'].unique(), \n",
    "    dfMaster['messageType'].value_counts(), \n",
    "    align='center'\n",
    ")\n",
    "barAll.set_title('All emails')\n",
    "\n",
    "barNonNull.bar(\n",
    "    dfMaster[dfMaster['messageStr'].notnull()]['messageType'].unique(), \n",
    "    dfMaster[dfMaster['messageStr'].notnull()]['messageType'].value_counts(), \n",
    "    align='center'\n",
    ")\n",
    "\n",
    "barNonNull.set_title('Non null meassages')\n",
    "\n",
    "barNull.bar(\n",
    "    dfMaster[dfMaster['messageStr'].isnull()]['messageType'].unique(), \n",
    "    dfMaster[dfMaster['messageStr'].isnull()]['messageType'].value_counts(), \n",
    "    align='center'\n",
    ")\n",
    "\n",
    "barNull.set_title('Null meassages')\n",
    "\n",
    "fig.text(0.5, 0.04, 'Email Type', ha='center', fontsize=15)\n",
    "fig.text(0.04, 0.5, 'Emails', va='center', rotation='vertical', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWordsG = pd.DataFrame(list(dict(count).items()))\n",
    "dfWordsG.columns = ['word', 'occur'] \n",
    "totalOcurrG = dfWordsG['occur'].sum()\n",
    "dfWordsG['freq'] = dfWordsG['occur'] / totalOcurrG  \n",
    "dfWordsG = dfWordsG.sort_values(by='freq', ascending=False)\n",
    "dfWordsG = dfWordsG.reset_index(drop=True)\n",
    "dfWordsG['freqAcum'] = dfWordsG['freq'].cumsum()\n",
    "\n",
    "dfSpamWordsG = pd.DataFrame(list(dict(countSpam).items()))\n",
    "dfSpamWordsG.columns = ['word', 'occur'] \n",
    "totalSpamOcurrG = dfSpamWordsG['occur'].sum()\n",
    "dfSpamWordsG['freq'] = dfSpamWordsG['occur'] / totalOcurrG  \n",
    "dfSpamWordsG = dfSpamWordsG.sort_values(by='freq', ascending=False)\n",
    "dfSpamWordsG = dfSpamWordsG.reset_index(drop=True)\n",
    "dfSpamWordsG['freqAcum'] = dfSpamWordsG['freq'].cumsum()\n",
    "\n",
    "dfHamWordsG = pd.DataFrame(list(dict(countHam).items()))\n",
    "dfHamWordsG.columns = ['word', 'occur'] \n",
    "totalHamOcurrG = dfHamWordsG['occur'].sum()\n",
    "dfHamWordsG['freq'] = dfHamWordsG['occur'] / totalOcurrG  \n",
    "dfHamWordsG = dfHamWordsG.sort_values(by='freq', ascending=False)\n",
    "dfHamWordsG = dfHamWordsG.reset_index(drop=True)\n",
    "dfHamWordsG['freqAcum'] = dfHamWordsG['freq'].cumsum()\n",
    "\n",
    "fig = plt.figure(figsize = (18,6))\n",
    "grid = plt.GridSpec(1,3, wspace =0.2)\n",
    "pltTotal = fig.add_subplot(grid[0,0])\n",
    "pltSpam = fig.add_subplot(grid[0,1])\n",
    "pltHam = fig.add_subplot(grid[0,2])\n",
    "\n",
    "pltTotal.plot(dfWords['freqAcum'], range(len(dfWordsG)))\n",
    "pltTotal.set_ylabel('Total Words')\n",
    "pltTotal.set_xlabel('Acumulative Frequence')\n",
    "pltTotal.set_title('All Words')\n",
    "pltTotal.grid(True)\n",
    "\n",
    "pltSpam.plot(dfSpamWords['freqAcum'], range(len(dfSpamWordsG)))\n",
    "pltSpam.set_ylabel('Total Spam Words')\n",
    "pltSpam.set_xlabel('Acumulative Frequence')\n",
    "pltSpam.set_title('Spam Words')\n",
    "pltSpam.grid(True)\n",
    "\n",
    "pltHam.plot(dfHamWords['freqAcum'], range(len(dfHamWordsG)))\n",
    "pltHam.set_ylabel('Total Ham Words')\n",
    "pltHam.set_xlabel('Acumulative Frequence')\n",
    "pltHam.set_title('Ham Words')\n",
    "pltHam.grid(True)\n",
    "\n",
    "\n",
    "fig2 = plt.figure(figsize = (18,6))\n",
    "grid2 = plt.GridSpec(1,6, wspace =0.4)\n",
    "\n",
    "pltTotalTableG = fig2.add_subplot(grid2[0,0:2])\n",
    "pltSpamTableG = fig2.add_subplot(grid2[0,2:4])\n",
    "pltHamTableG = fig2.add_subplot(grid2[0,4:6])\n",
    "\n",
    "dfTWordG = dfWordsG.loc[[0,50,100,500,1000,5000,10000,15000]][['freqAcum']]\n",
    "\n",
    "pltTotalTableG.table(cellText=dfTWordG.values, rowLabels= dfTWordG.index, colLabels = dfTWordG.columns, loc='best')\n",
    "pltTotalTableG.axis('off')\n",
    "\n",
    "dfSWordG = dfSpamWordsG.loc[[0,50,100,500,1000,5000,10000,15000]][['freqAcum']]\n",
    "\n",
    "pltSpamTableG.table(cellText=dfSWordG.values, rowLabels= dfSWordG.index, colLabels = dfSWordG.columns, loc='best')\n",
    "pltSpamTableG.axis('off')\n",
    "\n",
    "dfHWordG = dfHamWordsG.loc[[0,50,100,500,1000,5000,10000,15000]][['freqAcum']]\n",
    "\n",
    "pltHamTableG.table(cellText=dfHWordG.values, rowLabels= dfHWordG.index, colLabels = dfHWordG.columns, loc='best')\n",
    "pltHamTableG.axis('off')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patternStop = re.compile(r'\\b(' + r'|'.join(text.ENGLISH_STOP_WORDS) + r')\\b\\s*')\n",
    "text = patternStop.sub(' ', text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie([len(dfMaster[dfMaster['messageStr'].notnull()]), len(dfMaster[dfMaster['messageStr'].isnull()])], \n",
    "        labels=['Non Null', 'Null'], autopct='%1.0f%%', pctdistance=0.5, labeldistance=1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt.ENGLISH_STOP_WORDS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
